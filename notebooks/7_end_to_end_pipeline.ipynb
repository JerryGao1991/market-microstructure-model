{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Pipeline\n",
    "## Complete Workflow: Raw Data → Predictions → Strategy → Evaluation\n",
    "\n",
    "This notebook demonstrates the complete Market Microstructure Modeling pipeline:\n",
    "\n",
    "1. **Data Preprocessing**: Clean and validate raw L2 data\n",
    "2. **Feature Engineering**: Extract microstructure features\n",
    "3. **Model Training**: Train DeepLOB or use baselines\n",
    "4. **Strategy Execution**: Convert signals to trades\n",
    "5. **Performance Evaluation**: Calculate P&L, TCA, and metrics\n",
    "6. **Reporting**: Generate visualizations and reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.config import *\n",
    "from utils.io_utils import read_parquet, write_parquet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Market Microstructure Modeling Platform\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing\n",
    "### Load, clean, and validate raw order book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.zero_data_preprocessing import (\n",
    "    preprocess_orderbook, preprocess_trades, OrderBookValidator, DataCleaner\n",
    ")\n",
    "from utils.io_utils import read_instrument_info, read_trading_calendar\n",
    "\n",
    "# Configuration\n",
    "date = \"2025-09-15\"\n",
    "instrument_id = \"AAPL.P.XNAS\"\n",
    "\n",
    "print(f\"Processing: {instrument_id} on {date}\")\n",
    "print(\"\\nStep 1: Data Preprocessing\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check if raw data exists\n",
    "raw_file = ORDERBOOK_SNAPSHOTS_PATH / f\"date={date}\" / f\"instrument_id={instrument_id}.csv\"\n",
    "\n",
    "if raw_file.exists():\n",
    "    # Load metadata\n",
    "    instrument_info = read_instrument_info(INSTRUMENT_INFO_PATH)\n",
    "    calendar = read_trading_calendar(TRADING_CALENDAR_PATH)\n",
    "    \n",
    "    # Preprocess orderbook\n",
    "    df_orderbook = preprocess_orderbook(\n",
    "        date=date,\n",
    "        instrument_id=instrument_id,\n",
    "        instrument_info=instrument_info,\n",
    "        calendar=calendar,\n",
    "        output_path=INTERIM_DATA_PATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Preprocessed order book: {df_orderbook.shape}\")\n",
    "    print(f\"Time range: {df_orderbook['ts_event'].min()} to {df_orderbook['ts_event'].max()}\")\n",
    "else:\n",
    "    print(f\"Raw data not found: {raw_file}\")\n",
    "    print(\"Using synthetic data for demonstration...\")\n",
    "    \n",
    "    # Generate synthetic order book data\n",
    "    n_samples = 1000\n",
    "    df_orderbook = pd.DataFrame({\n",
    "        'ts_event': pd.date_range('2025-09-15 09:30:00', periods=n_samples, freq='100ms'),\n",
    "        'instrument_id': instrument_id,\n",
    "        'venue': 'XNAS',\n",
    "    })\n",
    "    \n",
    "    # Generate order book levels\n",
    "    base_price = 150.0\n",
    "    for i in range(1, N_LEVELS + 1):\n",
    "        df_orderbook[f'bid_px_{i}'] = base_price - (i-1) * 0.01 + np.random.randn(n_samples) * 0.01\n",
    "        df_orderbook[f'bid_sz_{i}'] = np.random.randint(10, 200, n_samples)\n",
    "        df_orderbook[f'ask_px_{i}'] = base_price + (i-1) * 0.01 + np.random.randn(n_samples) * 0.01\n",
    "        df_orderbook[f'ask_sz_{i}'] = np.random.randint(10, 200, n_samples)\n",
    "    \n",
    "    df_orderbook['mid_px'] = (df_orderbook['bid_px_1'] + df_orderbook['ask_px_1']) / 2\n",
    "    df_orderbook['spread_bps'] = ((df_orderbook['ask_px_1'] - df_orderbook['bid_px_1']) / df_orderbook['mid_px']) * 10000\n",
    "    \n",
    "    print(f\"Generated synthetic data: {df_orderbook.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "### Extract microstructure features (OFI, Microprice, Imbalance, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.one_feature_engineering import FeatureExtractor, create_labels\n",
    "\n",
    "print(\"\\nStep 2: Feature Engineering\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Extract features\n",
    "extractor = FeatureExtractor(n_levels=N_LEVELS)\n",
    "df_features = extractor.extract_all_features(df_orderbook)\n",
    "\n",
    "print(f\"Features extracted: {len(df_features.columns)} columns\")\n",
    "print(f\"\\nKey features:\")\n",
    "feature_cols = [c for c in df_features.columns if c not in ['ts_event', 'instrument_id', 'venue']]\n",
    "print(feature_cols[:15])\n",
    "\n",
    "# Create labels for supervised learning\n",
    "df_features = create_labels(df_features)\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_features['label'].value_counts())\n",
    "print(f\"\\nFinal dataset shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training/Loading\n",
    "### Train deep learning model or use baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.three_model_baselines import AvellanedaStoikov\n",
    "\n",
    "print(\"\\nStep 3: Model Selection\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# For demonstration, use Avellaneda-Stoikov baseline\n",
    "# In practice, load trained DeepLOB or Transformer model\n",
    "\n",
    "print(\"Using Avellaneda-Stoikov baseline for demonstration\")\n",
    "as_model = AvellanedaStoikov(\n",
    "    gamma=0.1,\n",
    "    k=1.5,\n",
    "    T=1.0,\n",
    "    max_inventory=100\n",
    ")\n",
    "\n",
    "# Generate simple predictions based on imbalance\n",
    "# In practice, use model.predict()\n",
    "df_features['signal_prob_up'] = 0.5 + df_features['imbalance_L1'] * 0.3\n",
    "df_features['signal_prob_down'] = 0.5 - df_features['imbalance_L1'] * 0.3\n",
    "df_features['signal_prob_neutral'] = 1 - df_features['signal_prob_up'] - df_features['signal_prob_down']\n",
    "\n",
    "# Clip probabilities\n",
    "df_features['signal_prob_up'] = df_features['signal_prob_up'].clip(0, 1)\n",
    "df_features['signal_prob_down'] = df_features['signal_prob_down'].clip(0, 1)\n",
    "\n",
    "print(\"Signal probabilities generated\")\n",
    "print(f\"Mean prob up: {df_features['signal_prob_up'].mean():.3f}\")\n",
    "print(f\"Mean prob down: {df_features['signal_prob_down'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Strategy Execution\n",
    "### Convert signals to trading actions with risk management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.five_strategy_engine import StrategyEngine\n",
    "\n",
    "print(\"\\nStep 4: Strategy Execution\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Initialize strategy\n",
    "strategy = StrategyEngine(instrument_id)\n",
    "\n",
    "# Simulate trading\n",
    "trades = []\n",
    "positions = []\n",
    "\n",
    "for idx in range(min(500, len(df_features))):\n",
    "    row = df_features.iloc[idx]\n",
    "    \n",
    "    # Create prediction probability array\n",
    "    pred_proba = np.array([\n",
    "        row['signal_prob_down'],\n",
    "        row['signal_prob_neutral'],\n",
    "        row['signal_prob_up']\n",
    "    ])\n",
    "    \n",
    "    # Generate signal\n",
    "    signal = strategy.generate_signal(row['ts_event'], pred_proba)\n",
    "    \n",
    "    if signal is not None and signal.direction != \"NEUTRAL\":\n",
    "        # Convert to order\n",
    "        order = strategy.signal_to_order(\n",
    "            signal,\n",
    "            current_bid=row['bid_px_1'],\n",
    "            current_ask=row['ask_px_1'],\n",
    "            mid_price=row['mid_px']\n",
    "        )\n",
    "        \n",
    "        if order is not None:\n",
    "            # Simulate fill\n",
    "            fill_price = order.price\n",
    "            strategy.process_fill(order, fill_price, order.quantity)\n",
    "            \n",
    "            trades.append({\n",
    "                'timestamp': row['ts_event'],\n",
    "                'side': order.side.value,\n",
    "                'price': fill_price,\n",
    "                'quantity': order.quantity,\n",
    "                'signal_strength': signal.strength\n",
    "            })\n",
    "    \n",
    "    # Update unrealized P&L\n",
    "    strategy.calculate_unrealized_pnl(row['mid_px'])\n",
    "    \n",
    "    # Record position\n",
    "    positions.append({\n",
    "        'timestamp': row['ts_event'],\n",
    "        'quantity': strategy.position.quantity,\n",
    "        'realized_pnl': strategy.position.realized_pnl,\n",
    "        'unrealized_pnl': strategy.position.unrealized_pnl,\n",
    "        'total_pnl': strategy.position.realized_pnl + strategy.position.unrealized_pnl\n",
    "    })\n",
    "\n",
    "trades_df = pd.DataFrame(trades)\n",
    "positions_df = pd.DataFrame(positions)\n",
    "\n",
    "print(f\"Total trades executed: {len(trades_df)}\")\n",
    "print(f\"Final position: {strategy.position.quantity}\")\n",
    "print(f\"Realized P&L: ${strategy.position.realized_pnl:.2f}\")\n",
    "print(f\"Unrealized P&L: ${strategy.position.unrealized_pnl:.2f}\")\n",
    "print(f\"Total P&L: ${strategy.position.realized_pnl + strategy.position.unrealized_pnl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Performance Evaluation\n",
    "### Calculate comprehensive performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics_utils import calculate_performance_summary\n",
    "\n",
    "print(\"\\nStep 5: Performance Evaluation\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate returns\n",
    "positions_df['returns'] = positions_df['total_pnl'].pct_change().fillna(0)\n",
    "\n",
    "# Performance summary\n",
    "perf_summary = calculate_performance_summary(\n",
    "    positions_df['returns'],\n",
    "    trades_df if len(trades_df) > 0 else None\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "for key, value in perf_summary.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualization\n",
    "### Generate key performance charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P&L Evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Cumulative P&L\n",
    "axes[0, 0].plot(positions_df['timestamp'], positions_df['total_pnl'], linewidth=2)\n",
    "axes[0, 0].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0, 0].set_ylabel('Total P&L ($)')\n",
    "axes[0, 0].set_title('Cumulative P&L')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Position size over time\n",
    "axes[0, 1].plot(positions_df['timestamp'], positions_df['quantity'], linewidth=1)\n",
    "axes[0, 1].axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0, 1].set_ylabel('Position Size')\n",
    "axes[0, 1].set_title('Position Evolution')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Trade distribution\n",
    "if len(trades_df) > 0:\n",
    "    axes[1, 0].hist(trades_df['quantity'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Trade Size')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Trade Size Distribution')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Returns distribution\n",
    "axes[1, 1].hist(positions_df['returns'].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].axvline(0, color='red', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Returns')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Returns Distribution')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Report\n",
    "### Create summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eight_reporting import PerformanceReporter\n",
    "\n",
    "print(\"\\nStep 7: Reporting\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "reporter = PerformanceReporter(output_path=CHARTS_PATH)\n",
    "\n",
    "# Generate reports\n",
    "results = {\n",
    "    'pnl_summary': {\n",
    "        'total_net_pnl': positions_df['total_pnl'].iloc[-1],\n",
    "        'num_trades': len(trades_df),\n",
    "        'final_position': strategy.position.quantity\n",
    "    },\n",
    "    'performance': perf_summary,\n",
    "    'tca': {\n",
    "        'avg_slippage_bps': 1.2,  # Placeholder\n",
    "        'avg_total_cost_bps': 2.8   # Placeholder\n",
    "    }\n",
    "}\n",
    "\n",
    "reporter.generate_summary_report(results)\n",
    "print(\"Summary report generated\")\n",
    "\n",
    "# Save outputs\n",
    "positions_df.to_csv(REPORTS_PATH / \"positions.csv\", index=False)\n",
    "if len(trades_df) > 0:\n",
    "    trades_df.to_csv(REPORTS_PATH / \"trades.csv\", index=False)\n",
    "\n",
    "print(\"\\nOutputs saved to:\")\n",
    "print(f\"  - {REPORTS_PATH / 'positions.csv'}\")\n",
    "print(f\"  - {REPORTS_PATH / 'trades.csv'}\")\n",
    "print(f\"  - {REPORTS_PATH / 'summary_report.md'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Pipeline Complete!\n",
    "\n",
    "We have successfully demonstrated the full pipeline:\n",
    "\n",
    "1. **Data Preprocessing**: Cleaned and validated order book data\n",
    "2. **Feature Engineering**: Extracted 50+ microstructure features\n",
    "3. **Model Application**: Generated trading signals\n",
    "4. **Strategy Execution**: Executed trades with risk controls\n",
    "5. **Performance Evaluation**: Calculated comprehensive metrics\n",
    "6. **Reporting**: Generated visualizations and reports\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Fine-tune model hyperparameters\n",
    "- Test on multiple instruments and time periods\n",
    "- Optimize transaction costs\n",
    "- Run capacity analysis\n",
    "- Deploy to production environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
