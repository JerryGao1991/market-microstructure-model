{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Deep Dive\n",
    "## Microstructure Features: OFI, Microprice, Imbalance, and More\n",
    "\n",
    "This notebook provides detailed analysis of:\n",
    "- Order Flow Imbalance (OFI) calculation and interpretation\n",
    "- Microprice vs mid-price\n",
    "- Queue imbalance at multiple levels\n",
    "- Volume and volatility features\n",
    "- Feature correlations and importance\n",
    "- Predictive power analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from src.config import *\n",
    "from utils.feature_utils import (\n",
    "    calculate_microprice, calculate_spread, calculate_queue_imbalance,\n",
    "    calculate_ofi, calculate_depth_imbalance\n",
    ")\n",
    "from utils.io_utils import read_parquet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Order Book Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed order book data\n",
    "date = \"2025-09-15\"\n",
    "instrument_id = \"AAPL.P.XNAS\"\n",
    "\n",
    "file_path = INTERIM_DATA_PATH / f\"date={date}\" / f\"{instrument_id}.parquet\"\n",
    "\n",
    "# Generate synthetic data if file doesn't exist\n",
    "if file_path.exists():\n",
    "    df = read_parquet(file_path)\n",
    "else:\n",
    "    print(\"Generating synthetic order book data...\")\n",
    "    n_samples = 2000\n",
    "    base_price = 150.0\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'ts_event': pd.date_range('2025-09-15 09:30:00', periods=n_samples, freq='100ms')\n",
    "    })\n",
    "    \n",
    "    # Generate order book levels with realistic dynamics\n",
    "    for i in range(1, N_LEVELS + 1):\n",
    "        df[f'bid_px_{i}'] = base_price - (i-1) * 0.01 + np.cumsum(np.random.randn(n_samples) * 0.001)\n",
    "        df[f'bid_sz_{i}'] = np.maximum(np.random.randint(50, 200, n_samples) + np.random.randn(n_samples) * 20, 10)\n",
    "        df[f'ask_px_{i}'] = base_price + (i-1) * 0.01 + np.cumsum(np.random.randn(n_samples) * 0.001)\n",
    "        df[f'ask_sz_{i}'] = np.maximum(np.random.randint(50, 200, n_samples) + np.random.randn(n_samples) * 20, 10)\n",
    "\n",
    "print(f\"Loaded {len(df)} order book snapshots\")\n",
    "print(f\"Time range: {df['ts_event'].min()} to {df['ts_event'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Microprice Analysis\n",
    "### Volume-weighted mid price vs simple mid price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate microprice and mid price\n",
    "df['microprice'] = calculate_microprice(\n",
    "    df['bid_px_1'].values,\n",
    "    df['bid_sz_1'].values,\n",
    "    df['ask_px_1'].values,\n",
    "    df['ask_sz_1'].values,\n",
    "    method=\"weighted\"\n",
    ")\n",
    "\n",
    "df['mid_price'] = (df['bid_px_1'] + df['ask_px_1']) / 2\n",
    "df['microprice_diff'] = df['microprice'] - df['mid_price']\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Price comparison\n",
    "axes[0].plot(df['ts_event'][:500], df['mid_price'][:500], \n",
    "             label='Mid Price', linewidth=1, alpha=0.7)\n",
    "axes[0].plot(df['ts_event'][:500], df['microprice'][:500], \n",
    "             label='Microprice', linewidth=1, alpha=0.7)\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].set_title('Microprice vs Mid Price')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Difference distribution\n",
    "axes[1].hist(df['microprice_diff'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(0, color='red', linestyle='--')\n",
    "axes[1].axvline(df['microprice_diff'].mean(), color='green', linestyle='--',\n",
    "                label=f\"Mean: {df['microprice_diff'].mean():.6f}\")\n",
    "axes[1].set_xlabel('Microprice - Mid Price')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Microprice Deviation from Mid Price')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Microprice statistics:\")\n",
    "print(f\"  Mean difference: {df['microprice_diff'].mean():.6f}\")\n",
    "print(f\"  Std difference: {df['microprice_diff'].std():.6f}\")\n",
    "print(f\"  Correlation with future returns: (to be calculated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Order Flow Imbalance (OFI)\n",
    "### Multiple time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate OFI at different windows\n",
    "for window in [10, 50, 100]:\n",
    "    df[f'ofi_{window}'] = calculate_ofi(\n",
    "        df['bid_px_1'],\n",
    "        df['bid_sz_1'],\n",
    "        df['ask_px_1'],\n",
    "        df['ask_sz_1'],\n",
    "        window=window\n",
    "    )\n",
    "\n",
    "# Plot OFI at different scales\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "for idx, window in enumerate([10, 50, 100]):\n",
    "    col = f'ofi_{window}'\n",
    "    axes[idx].plot(df['ts_event'][:1000], df[col][:1000], linewidth=1)\n",
    "    axes[idx].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[idx].set_ylabel('OFI')\n",
    "    axes[idx].set_title(f'Order Flow Imbalance (window={window})')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# OFI statistics\n",
    "print(\"OFI Statistics:\")\n",
    "for window in [10, 50, 100]:\n",
    "    col = f'ofi_{window}'\n",
    "    print(f\"\\nWindow {window}:\")\n",
    "    print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "    print(f\"  Std: {df[col].std():.2f}\")\n",
    "    print(f\"  Skewness: {df[col].skew():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Queue Imbalance at Multiple Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate depth imbalance\n",
    "imbalance_df = calculate_depth_imbalance(df, n_levels=N_LEVELS)\n",
    "df = pd.concat([df, imbalance_df], axis=1)\n",
    "\n",
    "# Plot imbalance at different levels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, level in enumerate([1, 3, 5, 10]):\n",
    "    col = f'imbalance_L{level}'\n",
    "    if col in df.columns:\n",
    "        axes[idx].hist(df[col].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[idx].axvline(0, color='red', linestyle='--')\n",
    "        axes[idx].axvline(df[col].mean(), color='green', linestyle='--',\n",
    "                         label=f\"Mean: {df[col].mean():.3f}\")\n",
    "        axes[idx].set_xlabel('Imbalance')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].set_title(f'Imbalance at {level} Level(s)')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation between imbalance at different levels\n",
    "imbalance_cols = [f'imbalance_L{l}' for l in [1, 3, 5, 10] if f'imbalance_L{l}' in df.columns]\n",
    "if imbalance_cols:\n",
    "    corr_matrix = df[imbalance_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=1)\n",
    "    plt.title('Correlation: Imbalance Across Levels')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Volume and Spread Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aggregate volume features\n",
    "bid_cols = [f'bid_sz_{i}' for i in range(1, N_LEVELS + 1)]\n",
    "ask_cols = [f'ask_sz_{i}' for i in range(1, N_LEVELS + 1)]\n",
    "\n",
    "df['total_bid_volume'] = df[bid_cols].sum(axis=1)\n",
    "df['total_ask_volume'] = df[ask_cols].sum(axis=1)\n",
    "df['total_volume'] = df['total_bid_volume'] + df['total_ask_volume']\n",
    "df['volume_ratio'] = df['total_bid_volume'] / df['total_ask_volume']\n",
    "\n",
    "# Spread features\n",
    "spread_abs, spread_bps = calculate_spread(df['bid_px_1'].values, df['ask_px_1'].values)\n",
    "df['spread_abs'] = spread_abs\n",
    "df['spread_bps'] = spread_bps\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total volume over time\n",
    "axes[0, 0].plot(df['ts_event'][:1000], df['total_volume'][:1000], linewidth=1)\n",
    "axes[0, 0].set_ylabel('Total Volume')\n",
    "axes[0, 0].set_title('Total Order Book Volume')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume ratio\n",
    "axes[0, 1].plot(df['ts_event'][:1000], df['volume_ratio'][:1000], linewidth=1, color='purple')\n",
    "axes[0, 1].axhline(1.0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_ylabel('Volume Ratio (Bid/Ask)')\n",
    "axes[0, 1].set_title('Bid-Ask Volume Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Spread distribution\n",
    "axes[1, 0].hist(df['spread_bps'], bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "axes[1, 0].axvline(df['spread_bps'].median(), color='red', linestyle='--',\n",
    "                   label=f\"Median: {df['spread_bps'].median():.2f} bps\")\n",
    "axes[1, 0].set_xlabel('Spread (bps)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Spread Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume vs Spread\n",
    "axes[1, 1].scatter(df['total_volume'][:1000], df['spread_bps'][:1000], \n",
    "                   alpha=0.3, s=10)\n",
    "axes[1, 1].set_xlabel('Total Volume')\n",
    "axes[1, 1].set_ylabel('Spread (bps)')\n",
    "axes[1, 1].set_title('Volume vs Spread')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for correlation analysis\n",
    "key_features = [\n",
    "    'microprice_diff', 'ofi_10', 'ofi_50', 'ofi_100',\n",
    "    'imbalance_L1', 'imbalance_L3', 'imbalance_L5',\n",
    "    'spread_bps', 'total_volume', 'volume_ratio'\n",
    "]\n",
    "\n",
    "# Filter features that exist\n",
    "existing_features = [f for f in key_features if f in df.columns]\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df[existing_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "print(\"\\nHighly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            print(f\"  {corr_matrix.columns[i]} <-> {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predictive Power Analysis\n",
    "### Correlation with future price movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate future price change\n",
    "horizons = [5, 10, 50, 100]  # Forward-looking steps\n",
    "\n",
    "for horizon in horizons:\n",
    "    df[f'future_return_{horizon}'] = (\n",
    "        df['mid_price'].shift(-horizon) - df['mid_price']\n",
    "    ) / df['mid_price']\n",
    "\n",
    "# Calculate correlations\n",
    "predictive_features = ['microprice_diff', 'ofi_10', 'ofi_50', 'ofi_100',\n",
    "                       'imbalance_L1', 'imbalance_L3']\n",
    "predictive_features = [f for f in predictive_features if f in df.columns]\n",
    "\n",
    "correlations = pd.DataFrame(\n",
    "    index=predictive_features,\n",
    "    columns=[f'horizon_{h}' for h in horizons]\n",
    ")\n",
    "\n",
    "for feature in predictive_features:\n",
    "    for horizon in horizons:\n",
    "        corr = df[feature].corr(df[f'future_return_{horizon}'])\n",
    "        correlations.loc[feature, f'horizon_{horizon}'] = corr\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlations.astype(float), annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            linewidths=1, cbar_kws={\"label\": \"Correlation\"})\n",
    "plt.xlabel('Prediction Horizon (steps)')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Correlation with Future Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Predictive Power (avg abs correlation):\")\n",
    "avg_corr = correlations.astype(float).abs().mean(axis=1).sort_values(ascending=False)\n",
    "for feature, corr in avg_corr.items():\n",
    "    print(f\"  {feature:.<30} {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Microprice**: Provides better price discovery than simple mid-price, especially during high imbalance\n",
    "2. **OFI**: Stronger predictive power at shorter time windows (10-50 steps)\n",
    "3. **Queue Imbalance**: Level 1 imbalance is most predictive, deeper levels add marginal value\n",
    "4. **Volume Features**: Bid-ask volume ratio correlates with short-term price direction\n",
    "5. **Spread**: Widens during uncertainty, acts as liquidity indicator\n",
    "\n",
    "### Feature Importance Ranking:\n",
    "\n",
    "Based on predictive power analysis:\n",
    "1. OFI (short windows)\n",
    "2. Queue imbalance (Level 1)\n",
    "3. Microprice deviation\n",
    "4. Volume ratio\n",
    "5. Spread dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
